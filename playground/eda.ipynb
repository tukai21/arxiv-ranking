{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_files = sorted(glob('../data/arxiv/*'))\n",
    "scirate_files = sorted(glob('../data/scirate/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "arxiv_data = []\n",
    "for file in arxiv_files:\n",
    "    with open(file, 'r') as f:\n",
    "        arxiv_data.append(json.load(f))\n",
    "        \n",
    "print(len(arxiv_data))\n",
    "\n",
    "scirate_data = []\n",
    "for file in scirate_files:\n",
    "    with open(file, 'r') as f:\n",
    "        scirate_data.append(json.load(f))\n",
    "        \n",
    "print(len(scirate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'day_2018_03_30'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data[-1]['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'Abstract: Out-of-time-order correlation (OTOC) functions provide a powerful theoreticaltool for diagnosing chaos and the scrambling of information instrongly-interacting, quantum systems. However, their direct and unambiguousexperimental measurement remains an essential challenge. At its core, thischallenge arises from the fact that the effects of both decoherence andexperimental noise can mimic that of information scrambling, leading to decayof OTOCs. Here, we analyze a quantum teleportation protocol that explicitlyenables one to differentiate between scrambling and decoherence. Moreover, wedemonstrate that within this protocol, one can extract a precise \"noise\"parameter which quantitatively captures the non-scrambling induced decay ofOTOCs. Using this parameter, we prove explicit bounds on the true value of theOTOC. Our results open the door to experimentally measuring quantum scramblingwith built-in verifiability.',\n",
       " 'authors': ['Beni Yoshida', 'Norman Y. Yao'],\n",
       " 'num_versions': 1,\n",
       " 'order': 0,\n",
       " 'paper_link': 'https://arxiv.org/abs/1803.10772',\n",
       " 'size': '5973kb',\n",
       " 'submit_time': '18:00:00',\n",
       " 'submit_weekday': 'Wed',\n",
       " 'title': 'Disentangling Scrambling and Decoherence via Quantum Teleportation'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2018-03-30 Arxiv top\n",
    "arxiv_data[-1]['papers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': ['Beni Yoshida', 'Norman Y. Yao'],\n",
       " 'rank': 0,\n",
       " 'scite_count': 34,\n",
       " 'title': 'Disentangling Scrambling and Decoherence via Quantum Teleportation'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2018-03-30 Scirate top\n",
    "scirate_data[-1]['papers'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entry ID: paper name (DOI?)\n",
    "We can create an arbitrary paper id that corresponds to each paper title, authors, and DOI.\n",
    "\n",
    "Possible features:\n",
    "\n",
    "- Arxiv order\n",
    "- Scirate order\n",
    "- Paper length (pages)\n",
    "- Title length (words)\n",
    "- Number of authors\n",
    "- Total # of citations of the authors (or first author? last author?)\n",
    "- Bag of Words of title\n",
    "- Bag of Words of abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain features from both Arxiv and Scirate paper lists\n",
    "\n",
    "index = []\n",
    "title = []\n",
    "authors = []\n",
    "num_authors = []\n",
    "title_length = []\n",
    "arxiv_order = []\n",
    "submit_time = []\n",
    "submit_weekday = []\n",
    "paper_size = []\n",
    "num_versions = []\n",
    "\n",
    "for res in arxiv_data:\n",
    "    date = res['date']\n",
    "    papers = res['papers']\n",
    "    for paper in papers:\n",
    "        # create arbitrary paper id - currently, it is \"date + Arxiv order\"\n",
    "        if paper['order'] < 10:\n",
    "            idx = '_000' + str(paper['order'])\n",
    "        elif 10 <= paper['order'] < 100:\n",
    "            idx = '_00' + str(paper['order'])\n",
    "        elif 100 <= paper['order'] < 1000:\n",
    "            idx = '_0' + str(paper['order'])\n",
    "        else:\n",
    "            idx = '_' + str(paper['order'])\n",
    "        index.append(date + idx)\n",
    "        \n",
    "        title.append(paper['title'])\n",
    "        authors.append(paper['authors'])\n",
    "        num_authors.append(len(paper['authors']))\n",
    "        title_length.append(len(paper['title']))\n",
    "        arxiv_order.append(paper['order'])\n",
    "        submit_time.append(paper['submit_time'])\n",
    "        submit_weekday.append(paper['submit_weekday'])\n",
    "        paper_size.append(int(re.findall('\\d+', paper['size'])[0]))\n",
    "        num_versions.append(paper['num_versions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1727"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scirate rank - string matching to find index of each paper in Arxiv list\n",
    "### This process is pretty slow - needs to be refactored ###\n",
    "\n",
    "scirate_rank = [-1 for _ in range(len(index))]\n",
    "scite_score = [-1 for _ in range(len(index))]\n",
    "\n",
    "for res in scirate_data:\n",
    "    papers = res['papers']\n",
    "    for paper in papers:\n",
    "        title_sci = paper['title']\n",
    "        try:\n",
    "            idx = title.index(title_sci)\n",
    "        except:\n",
    "            # if there is no just match, use difflib SequenceMatcher for title matching\n",
    "            str_match = np.array([SequenceMatcher(a=title_sci, b=title_arx).ratio() for title_arx in title])\n",
    "            idx = np.argmax(str_match)\n",
    "        scirate_rank[idx] = paper['rank']\n",
    "        scite_score[idx] = paper['scite_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for pandas DataFrame\n",
    "columns = ['title', 'authors', 'num_authors', 'title_length', 'arxiv_order', 'submit_time', 'submit_weekday',\n",
    "           'paper_size', 'num_versions', 'scirate_rank', 'scite_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is too dirty...\n",
    "title = np.array(title).reshape(-1, 1)\n",
    "authors = np.array(authors).reshape(-1, 1)\n",
    "num_authors = np.array(num_authors).reshape(-1, 1)\n",
    "title_length = np.array(title_length).reshape(-1, 1)\n",
    "arxiv_order = np.array(arxiv_order).reshape(-1, 1)\n",
    "submit_time = np.array(submit_time).reshape(-1, 1)\n",
    "submit_weekday = np.array(submit_weekday).reshape(-1, 1)\n",
    "paper_size = np.array(paper_size).reshape(-1, 1)\n",
    "num_versions = np.array(num_versions).reshape(-1, 1)\n",
    "scirate_rank = np.array(scirate_rank).reshape(-1, 1)\n",
    "scite_score = np.array(scite_score).reshape(-1, 1)\n",
    "\n",
    "data = np.concatenate([\n",
    "    title,\n",
    "    authors,\n",
    "    num_authors,\n",
    "    title_length,\n",
    "    arxiv_order,\n",
    "    submit_time,\n",
    "    submit_weekday,\n",
    "    paper_size,\n",
    "    num_versions,\n",
    "    scirate_rank,\n",
    "    scite_score\n",
    "], axis=1)\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>title_length</th>\n",
       "      <th>arxiv_order</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>submit_weekday</th>\n",
       "      <th>paper_size</th>\n",
       "      <th>num_versions</th>\n",
       "      <th>scirate_rank</th>\n",
       "      <th>scite_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day_2018_01_01_0000</th>\n",
       "      <td>Harvesting Entanglement from the Black Hole Va...</td>\n",
       "      <td>[Laura J. Henderson, Robie A. Hennigar, Robert...</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>Thu</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_2018_01_01_0001</th>\n",
       "      <td>Suppression of heating in quantum spin cluster...</td>\n",
       "      <td>[Kai Ji, Boris V. Fine]</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>19:10:19</td>\n",
       "      <td>Thu</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_2018_01_01_0002</th>\n",
       "      <td>Simulating boson sampling in lossy architectures</td>\n",
       "      <td>[Raúl García-Patrón, Jelmer J. Renema, Valery ...</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>19:52:42</td>\n",
       "      <td>Thu</td>\n",
       "      <td>1107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_2018_01_01_0003</th>\n",
       "      <td>Local Casimir Effect for a Scalar Field in Pre...</td>\n",
       "      <td>[Davide Fermi (Universita' di Milano), Livio P...</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>19:58:14</td>\n",
       "      <td>Thu</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_2018_01_01_0004</th>\n",
       "      <td>Emerging Connections: Quantum and Classical Op...</td>\n",
       "      <td>[Xiao-Feng Qian, A. Nick Vamivakas, Joseph H. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>20:01:22</td>\n",
       "      <td>Thu</td>\n",
       "      <td>6095</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 title  \\\n",
       "day_2018_01_01_0000  Harvesting Entanglement from the Black Hole Va...   \n",
       "day_2018_01_01_0001  Suppression of heating in quantum spin cluster...   \n",
       "day_2018_01_01_0002   Simulating boson sampling in lossy architectures   \n",
       "day_2018_01_01_0003  Local Casimir Effect for a Scalar Field in Pre...   \n",
       "day_2018_01_01_0004  Emerging Connections: Quantum and Classical Op...   \n",
       "\n",
       "                                                               authors  \\\n",
       "day_2018_01_01_0000  [Laura J. Henderson, Robie A. Hennigar, Robert...   \n",
       "day_2018_01_01_0001                            [Kai Ji, Boris V. Fine]   \n",
       "day_2018_01_01_0002  [Raúl García-Patrón, Jelmer J. Renema, Valery ...   \n",
       "day_2018_01_01_0003  [Davide Fermi (Universita' di Milano), Livio P...   \n",
       "day_2018_01_01_0004  [Xiao-Feng Qian, A. Nick Vamivakas, Joseph H. ...   \n",
       "\n",
       "                    num_authors title_length arxiv_order submit_time  \\\n",
       "day_2018_01_01_0000           5           50           0    19:00:00   \n",
       "day_2018_01_01_0001           2          104           1    19:10:19   \n",
       "day_2018_01_01_0002           3           48           2    19:52:42   \n",
       "day_2018_01_01_0003           2           71           3    19:58:14   \n",
       "day_2018_01_01_0004           3           50           4    20:01:22   \n",
       "\n",
       "                    submit_weekday paper_size num_versions scirate_rank  \\\n",
       "day_2018_01_01_0000            Thu        118            1            7   \n",
       "day_2018_01_01_0001            Thu        238            1           23   \n",
       "day_2018_01_01_0002            Thu       1107            1            1   \n",
       "day_2018_01_01_0003            Thu        125            1           22   \n",
       "day_2018_01_01_0004            Thu       6095            1           21   \n",
       "\n",
       "                    scite_score  \n",
       "day_2018_01_01_0000           3  \n",
       "day_2018_01_01_0001           0  \n",
       "day_2018_01_01_0002          16  \n",
       "day_2018_01_01_0003           0  \n",
       "day_2018_01_01_0004           0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arxiv_order</th>\n",
       "      <th>scite_score</th>\n",
       "      <th>scirate_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arxiv_order</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>-0.042569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scite_score</th>\n",
       "      <td>0.008668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.810787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scirate_rank</th>\n",
       "      <td>-0.042569</td>\n",
       "      <td>-0.810787</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              arxiv_order  scite_score  scirate_rank\n",
       "arxiv_order      1.000000     0.008668     -0.042569\n",
       "scite_score      0.008668     1.000000     -0.810787\n",
       "scirate_rank    -0.042569    -0.810787      1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['arxiv_order', 'scite_score', 'scirate_rank']].astype(float).corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
